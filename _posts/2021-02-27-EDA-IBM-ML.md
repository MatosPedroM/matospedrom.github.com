---
layout: post
title: "Exploratory Data Analysis for Machine Learning - IBM ML Course Project"
categories: forecast, exploratory data analysis
---


# Exploratory Data Analysis for Machine Learning - Course Project


```python
import warnings 
warnings.filterwarnings(action='ignore')

from pandas import read_csv
import pandas as pd
import numpy as np
import datetime

import matplotlib.pyplot as plt
%matplotlib inline
#import matplotlib.gridspec as gridspec
#plt.rcParams.update({'font.size': 12})

import seaborn as sns
sns.set_style("white")
sns.set_context('notebook')
```

## Brief description of the data set and a summary of its attributes

The dataset contains the national power load information that can be download from the Portuguese Electrical Transmission System Operator - REN following this [link](https://www.mercado.ren.pt/PT/Electr/InfoMercado/Consumo/Paginas/Verif.aspx).


## Initial plan for data exploration

The retrieved information contains:
- Date (dd-mm-yyy)
- Hour 
- Load ... national power load, in MWh
- Market Load ... national power load plus the power plant ancillary consumptions, i.e., the total national load, in MWh

As we will be dealing with a time-series, we will analyze the behavior of the total national load across several timer intervals (years, months, days, hours and days of the week) searching for specific patterns


```python
df=pd.read_csv('national_load_2015_2020.csv', sep=';', decimal=',')
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>DATE</th>
      <th>HOUR</th>
      <th>LOAD</th>
      <th>MARKET LOAD</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>01-01-2015</td>
      <td>1</td>
      <td>5605.473</td>
      <td>5613.290</td>
    </tr>
    <tr>
      <th>1</th>
      <td>01-01-2015</td>
      <td>2</td>
      <td>5340.470</td>
      <td>5351.188</td>
    </tr>
    <tr>
      <th>2</th>
      <td>01-01-2015</td>
      <td>3</td>
      <td>5123.865</td>
      <td>5131.278</td>
    </tr>
    <tr>
      <th>3</th>
      <td>01-01-2015</td>
      <td>4</td>
      <td>4771.081</td>
      <td>4773.311</td>
    </tr>
    <tr>
      <th>4</th>
      <td>01-01-2015</td>
      <td>5</td>
      <td>4443.512</td>
      <td>4453.604</td>
    </tr>
  </tbody>
</table>
</div>



## Actions taken for data cleaning and feature engineering

The quality of data is very good so the is no need for any data cleaning.

For a simple data exploration, has we are dealing with time-series, we will:
1. Create a TIMESTAMP data column composed by the DATE and HOUR (we will be using UTC timezone)
2. Calculate the ANCILLIARY services load subtracting the LOAD to the MARKET LOAD


```python
df['DATE']=pd.to_datetime(df['DATE'], format='%d-%m-%Y')
df['TIMESTAMP'] = df.apply(lambda x: x['DATE']+datetime.timedelta(hours=x['HOUR']-1), axis=1)
df = df.set_index('TIMESTAMP').tz_localize('UTC')
df['ANCILLARY'] = df['MARKET LOAD'] - df['LOAD']
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>DATE</th>
      <th>HOUR</th>
      <th>LOAD</th>
      <th>MARKET LOAD</th>
      <th>ANCILLARY</th>
    </tr>
    <tr>
      <th>TIMESTAMP</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2015-01-01 00:00:00+00:00</th>
      <td>2015-01-01</td>
      <td>1</td>
      <td>5605.473</td>
      <td>5613.290</td>
      <td>7.817</td>
    </tr>
    <tr>
      <th>2015-01-01 01:00:00+00:00</th>
      <td>2015-01-01</td>
      <td>2</td>
      <td>5340.470</td>
      <td>5351.188</td>
      <td>10.718</td>
    </tr>
    <tr>
      <th>2015-01-01 02:00:00+00:00</th>
      <td>2015-01-01</td>
      <td>3</td>
      <td>5123.865</td>
      <td>5131.278</td>
      <td>7.413</td>
    </tr>
    <tr>
      <th>2015-01-01 03:00:00+00:00</th>
      <td>2015-01-01</td>
      <td>4</td>
      <td>4771.081</td>
      <td>4773.311</td>
      <td>2.230</td>
    </tr>
    <tr>
      <th>2015-01-01 04:00:00+00:00</th>
      <td>2015-01-01</td>
      <td>5</td>
      <td>4443.512</td>
      <td>4453.604</td>
      <td>10.092</td>
    </tr>
  </tbody>
</table>
</div>




```python
df.info()
```

    <class 'pandas.core.frame.DataFrame'>
    DatetimeIndex: 52608 entries, 2015-01-01 00:00:00+00:00 to 2020-12-31 23:00:00+00:00
    Data columns (total 5 columns):
     #   Column       Non-Null Count  Dtype         
    ---  ------       --------------  -----         
     0   DATE         52608 non-null  datetime64[ns]
     1   HOUR         52608 non-null  int64         
     2   LOAD         52608 non-null  float64       
     3   MARKET LOAD  52608 non-null  float64       
     4   ANCILLARY    52608 non-null  float64       
    dtypes: datetime64[ns](1), float64(3), int64(1)
    memory usage: 2.4 MB
    

## Exploratory Data analysis

Let's start to check the basic information about our prepared data set.


```python
df.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>HOUR</th>
      <th>LOAD</th>
      <th>MARKET LOAD</th>
      <th>ANCILLARY</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>52608.000000</td>
      <td>52608.000000</td>
      <td>52608.000000</td>
      <td>52608.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>12.500000</td>
      <td>5663.221732</td>
      <td>5680.300281</td>
      <td>17.078549</td>
    </tr>
    <tr>
      <th>std</th>
      <td>6.922252</td>
      <td>991.189512</td>
      <td>990.444095</td>
      <td>21.081083</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>3159.069000</td>
      <td>3165.953000</td>
      <td>-98.455000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>6.750000</td>
      <td>4817.936250</td>
      <td>4836.931500</td>
      <td>5.668000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>12.500000</td>
      <td>5627.830500</td>
      <td>5645.154500</td>
      <td>14.641500</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>18.250000</td>
      <td>6410.719000</td>
      <td>6424.144500</td>
      <td>26.611750</td>
    </tr>
    <tr>
      <th>max</th>
      <td>24.000000</td>
      <td>8849.793000</td>
      <td>8864.514000</td>
      <td>148.226000</td>
    </tr>
  </tbody>
</table>
</div>



We have roughly 6 years of hourly load information. 

The MARKET LOAD and LOAD are very similar (\~5700 MWh mean and \~990 MWh standard deviation). Also, as expected, the ANCILLARY values are very small (\~17 MWh mean) eq. to 0.3% of the hourly national load.

Let's start and plot both daily and hourly MARKET LOAD 


```python
plt.figure(figsize=(15,5))
plt.title('Daily Market Load, GWh')
sns.lineplot(data = df.resample('D')['MARKET LOAD'].sum()*1E-3)
plt.ylim([0,200])
plt.grid(), plt.tight_layout(), plt.show();
```


    
![png](output_11_0.png)
    



```python
#A month of daily market load
plt.figure(figsize=(15,5))
plt.title('Daily Market Load, GWh')
sns.lineplot(data = df.resample('D')['MARKET LOAD'].sum().iloc[:30]*1E-3)
plt.ylim([0,200])
plt.grid(), plt.tight_layout(), plt.show();
```


    
![png](output_12_0.png)
    


It's clear that there is a seasonal pattern across the seasons, a weekly pattern...


```python
#One month of hourly plot of the market load
plt.figure(figsize=(15,5))
plt.title('Hourly Market Load, MWh')
sns.lineplot(data = df['MARKET LOAD'].iloc[:24*30])
plt.grid(), plt.tight_layout(), plt.show();
```


    
![png](output_14_0.png)
    



```python
#One week hourly plot of the market load
plt.figure(figsize=(15,5))
plt.title('Hourly Market Load, MWh')
sns.lineplot(data = df['MARKET LOAD'].iloc[24*11:24*18])
plt.grid(), plt.tight_layout(), plt.show();
```


    
![png](output_15_0.png)
    


Also there is a clear hourly pattern during the days, with a different "level" (mean) between weekdays and weekends

Let's now plot the distributions of both daily and hourly MARKET LOAD


```python
#Distribution of the daily Market Load
plt.figure(figsize=(15,5))
sns.distplot(df.resample('D')['MARKET LOAD'].sum(), bins=200, kde=True)
plt.show()
```


    
![png](output_17_0.png)
    



```python
#Distribution of the hourly Market Load
plt.figure(figsize=(15,5))
sns.distplot(df['MARKET LOAD'], bins=200, kde=True)
plt.show()
```


    
![png](output_18_0.png)
    


Both don't seam to have a normal distribution... but we will test that later

Let's now explore a bit the ANCILLARY load


```python
plt.figure(figsize=(15,5))
plt.title('Ancillary Load, GWh')
sns.lineplot(data = df.resample('D')['ANCILLARY'].sum()*1E-3)
plt.grid(), plt.tight_layout(), plt.show();
```


    
![png](output_21_0.png)
    



```python
#One month of hourly plot of the ancillary load
plt.figure(figsize=(15,5))
plt.title('Ancillary Load, MWh')
sns.lineplot(data = df['ANCILLARY'].iloc[:24*30])
plt.grid(), plt.tight_layout(), plt.show();
```


    
![png](output_22_0.png)
    



```python
#One week hourly plot of the market load
plt.figure(figsize=(15,5))
plt.title('Hourly Ancillary Load, MWh')
sns.lineplot(data = df['ANCILLARY'].iloc[24*11:24*18])
plt.grid(), plt.tight_layout(), plt.show();
```


    
![png](output_23_0.png)
    



```python
plt.figure(figsize=(15,5))
sns.distplot(df['ANCILLARY'], bins=200, kde=True)
plt.show()
```


    
![png](output_24_0.png)
    



```python
#% of the ANCILLARY load values below 0
print('%.2f %%'% (df[df['ANCILLARY'] < 0]['ANCILLARY'].count() / df['ANCILLARY'].count()*100))
```

    15.43 %
    

It's clear the the ANCILARY load is very "noisy", without a specific pattern. Also noticeable that there are a some negative values (~15% of the dataset) that might reflect that part of the generation of the power plant are considered in the ANCILLARY load data series

Let's now see, for curiosity, the distribution of the MARKET LOAD by hour of the day


```python
f, ax = plt.subplots(5,5, figsize=(15, 10), sharey=True, sharex=True)

for i,_ in enumerate(df.index.hour.unique()):    
    col = i % 5
    row = int(i / 5)
    ax[row,col].set_title('H'+str(i+1))
    sns.distplot(df[df.index.hour==i]['MARKET LOAD'], kde=False, ax=ax[row,col])

for ax in f.axes:
    if ax.is_last_row():
        ax.set_xlabel('Market Load (MWh)')
    else:
        ax.set_xlabel('')
        
    if ax.is_first_col():
        ax.set_ylabel('Frequency')
    else:
        ax.set_ylabel('')
        
plt.tight_layout()
plt.show()
```


    
![png](output_27_0.png)
    


Except for a few hour of the day (from hours 3 to 7) that have "some kind of" normal distribution, the remaining tend to have two frequency peaks that is probably related to the weekday/weekend pattern load levels.

Let's now plot the MARKET LOAD by year, day of the week, month and hour of the day


```python
f, ax = plt.subplots(ncols=2,nrows=2, figsize=(15, 10), sharey=True, squeeze=False)

ax[0,0].set_title('Year')
sns.boxplot(y = df['MARKET LOAD'], x = df.index.year, data=df, ax=ax[0,0])
ax[0,0].grid()

ax[1,0].set_title('Month')
ax[1,0].grid()
sns.boxplot(y = df['MARKET LOAD'], x = df.index.month, data=df, ax=ax[1,0])


ax[0,1].set_title('Week')
ax[0,1].grid()
sns.boxplot(y = df['MARKET LOAD'], x = df.index.day_name(), data=df, ax=ax[0,1],
            order=['Monday','Tuesday', 'Wednesday','Thursday','Friday','Saturday','Sunday'])


ax[1,1].set_title('Hour')
ax[1,1].grid()
sns.boxplot(y = df['MARKET LOAD'], x = df.index.hour+1, data=df, ax=ax[1,1])

plt.show()

```


    
![png](output_29_0.png)
    


We can find that the yearly MARKET LOAD doesn't change that much with the exception of 2018... The are clear monthly, weekly and hourly patterns.


```python
#Total yearly MARKET LOAD in GWh
aux = df.resample('Y')['MARKET LOAD'].sum()*1E-3
print(aux)
print('\nmean: %.f GWh, std: %.f GWh' % (aux.mean(), aux.std()))
```

    TIMESTAMP
    2015-12-31 00:00:00+00:00    49071.107581
    2016-12-31 00:00:00+00:00    49489.076103
    2017-12-31 00:00:00+00:00    49778.463511
    2018-12-31 00:00:00+00:00    51050.522049
    2019-12-31 00:00:00+00:00    50478.398197
    2020-12-31 00:00:00+00:00    48961.669744
    Freq: A-DEC, Name: MARKET LOAD, dtype: float64
    
    mean: 49805 GWh, std: 819 GWh
    

## Key Findings and Insights, which synthesizes the results of Exploratory Data Analysis in an insightful and actionable manner

In conclusion:
- MARKET LOAD and LOAD are very similar (\~5700 MWh mean and \~990 MWh standard deviation). Also, as expected, the ANCILLARY values are very small (\~17 MWh mean) eq. to 0.3% of the hourly national load and sometimes (15%) below zero.
- The nation load (MARKET LOAD) tends to be the same every year \~50 000 GWh
- There is a clear monthly pattern with higher load levels in the winter and lower during the Spring/Autumn and an increase in July (yet below Winter levels)
- During the week the load tends to have the same average hourly level \~6000 MWh (Monday having some lower quartile observation probably due to the transition from Sunday) and the weekends have a lower load level ~-1000 MWh (5200 and 5000 MWh, on Saturday and Sunday)
- During the day, it's clear that there are 'peak' hours, from H10 to H23, with an average hourly load of 6200 MWh, and 'offpeak' hours, between H3 and H7, with and average hourly load of 4500 MWh.

All of these will have to be considered to build national load forecast model.

## Formulating at least 3 hypothesis about this data

1. Daily MARKET LOAD has normal distribution (H0)
2. Hourly MARKET LOAD has normal distribution (H0), and
3. Hourly ANCILLARY load has normal distribution (H0)

## Conducting a formal significance test for one of the hypotheses and discuss the results

Has we defined the hypotheses that the daily Market Load as a normal distribution (H0) we will us the Shapiro-Wilk test evaluates a data sample and quantifies how likely it is that the data was drawn from a Gaussian distribution.

The shapiro() SciPy function will calculate the Shapiro-Wilk and return both the W-statistic calculated by the test and the p-value.


```python
from scipy import stats
```


```python
def test_normality(data, alpha = 0.05):
    #Sample the dataset
    sampled_data = np.random.choice(data, size = 5000)
    #Calculate the statistics
    stat, p = stats.shapiro(sampled_data)
    print('Statistics=%.3f, p=%.7f' % (stat, p))
    #Evalutate if the reject or not the null hypotheses for the significance level defined or by default
    if p > alpha:
        print('Sample looks Gaussian (fail to reject H0)')
    else:
        print('Sample does not look Gaussian (reject H0)')
    
```


```python
#Test on the daily MARKET LOAD
data = df.resample('D')['MARKET LOAD'].sum()
test_normality(data)
```

    Statistics=0.993, p=0.0000000
    Sample does not look Gaussian (reject H0)
    


```python
#'Create' an normal distribution data with the mean and standard deviation of the daily MARKET LOAD
#and test it's "normality"
data = np.random.normal(loc=df['MARKET LOAD'].mean(), scale=df['MARKET LOAD'].std(), size=100000)
test_normality(data)
```

    Statistics=1.000, p=0.5899544
    Sample looks Gaussian (fail to reject H0)
    


```python
#Plot both distribution to visually see the differences
plt.figure(figsize=(15,5))
sns.distplot(df['MARKET LOAD'], bins=200, kde=True, label='MARKET LOAD')
sns.distplot(np.random.normal(loc=df['MARKET LOAD'].mean(), scale=df['MARKET LOAD'].std(), size=100000), bins=200, kde=True, label='Normal distribution');
plt.title('Daily MARKET LOAD and normal distribution with the MEAN and STD of the daily MARKET LOAD')
plt.xlabel('Load (MWh)')
plt.legend()
plt.show()
```


    
![png](output_39_0.png)
    


## Suggestions for next steps in analyzing this data
Has we seen an the load tends to be higher in the winter and summer months it would be interesting the understand the relation national load vs temperature.

Also, has we have seen, the national load tends to similarly like a Sunday during national holidays, so it would be important to classify those days accordingly.

## A paragraph that summarizes the quality of this data set and a request for additional data if needed

Has already stated the dataset is quite simple and has a good quality.
